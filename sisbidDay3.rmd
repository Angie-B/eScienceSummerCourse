---
title: "sisbidDay3"
author: "Angie Boysen"
date: "July 13, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##dplyr

```{r}
install.packages('gapminder')
library(dplyr)
library(gapminder)
str(gapminder)
gtbl = gapminder

```

filter
```{r}
glimpse(gtbl)
filter(gtbl, lifeExp < 29)
filter(gtbl, country == "Rwanda")
```


look at columns with select
```{r select}
select(gtbl,country,pop,continent)

```

look at arrange for re-ordering rows
```{r}
# arrange(gtbl,pop)
# arrange(gtbl,desc(pop)) #Order in reverse
arrange(gtbl, year, lifeExp) #Order by two things
```

Creating new variables with mutate
```{r}
gtbl = mutate(gtbl, newVar = (lifeExp / gdpPercap), newVar2 = newVar*2)
select(gtbl,lifeExp,gdpPercap,newVar)
distinct(gtbl) # spits out all unique rows - can detect duplucate rows/errors in database
```

sampling data with dplyr
```{r}
# set.seed(12345) #makes the randomness the same every time you run this
sample_n(gtbl,3) # 3 random rows
sample_frac(gtbl,0.5) # random 50%
```

## piping

all of these dplyr functions have the first argument as the dataframe
So if you chain a bunch of these together it works nicely because the output is always a dataframe that you can input into another function.

%>% -- read as "then"

These two pieces of code do the same thing:
```{r}
head(gtbl)
gtbl %>% head()
```

Example: show me a random sample of the data for asian countries with life expectancy < 65.
```{r}
gtbl1 <- gtbl[gtbl$continent =="Asia",]
gtbl2 <- gtbl1[gtbl1$lifeExp < 65,]
gtbl3 <- gtbl2[sample(1:dim(gtbl2)[1],size=10),]
gtbl3

## OR
random_sample <- gtbl %>% filter(continent =="Asia") %>%
     filter(lifeExp <65) %>%
     sample_n(10)
random_sample

## Can do Asia or Africa

random_sample <- gtbl %>% filter(continent %in% c("Asia","Africa")) %>%
     filter(lifeExp <65) %>%
     sample_n(10)
random_sample
```

Example2: Split, apply, combine

What is the average life expectancy by continent?

```{r}
gtbl %>% group_by(continent) %>% summarize(aveLife = mean(lifeExp))

## can do more than one thing
gtbl %>% group_by(continent) %>% 
     summarize(aveLife = mean(lifeExp), sdLife = sd(lifeExp))

## can definte your own fucntion to use
mean2 = function(x){mean(x/2)}

```

## dplyr lab
Download the samples data on the 1,000 genomes project: (https://www.dropbox.com/s/7bg2pvzmcv4di3v/1000genomes.xlsx?dl=0).
Read the Final Phase Sequence Data sheet. Only read the data for the low coverage samples.
```{r}
# install.packages("readxl")
library(readxl)
dat <- read_excel("1000genomes.xlsx",4, skip = 1)
dat <- dat[,1:7]
names(dat)
```

Calculate total sequence by platform

```{r}
unique(dat$Platform)
dat %>% group_by(Platform) %>% 
     summarize(totalSequence = sum(`Total Sequence`, na.rm = T))
```

Do the same thing by sequencing center
```{r}
dat %>% group_by(Center) %>% 
     summarize(totalSequence = sum(`Total Sequence`, na.rm = T))

```

Find the subset of samples that passed QC.

```{r}
filter(dat, !is.na(`Passed QC`))
```

Find the subset that passed QC and came from the BCM center
```{r}
dat %>% filter(!is.na(`Passed QC`)) %>%
     filter(Center == "BCM")
```

Calculate the average aligned coverage for each population on the subset of samples that passed QC that came from the BCM.
```{r}
dat %>% filter(!is.na(`Passed QC`)) %>%
     filter(Center == "BCM") %>% 
     group_by(Population) %>%
     summarize(AveAligned = mean(`Aligned Non Duplicated Coverage`))
```

if you want to pipe but the function doesn't have the dataframe as the first argument you use the dot (.) to tell the function where the data is. Example:
```{r lm}
dat %>% lm(`Total Sequence` ~ Center, data = .)
```

## Merging datasets
Superhero example
```{r}
superheroes <-
  c("    name, alignment, gender,         publisher",
    " Magneto,       bad,   male,            Marvel",
    "   Storm,      good, female,            Marvel",
    "Mystique,       bad, female,            Marvel",
    "  Batman,      good,   male,                DC",
    "   Joker,       bad,   male,                DC",
    "Catwoman,       bad, female,                DC",
    " Hellboy,      good,   male, Dark Horse Comics")

superheroes <- read.csv(text = superheroes, strip.white = TRUE)
superheroes

publishers <- 
  c("publisher, yr_founded",
    "       DC,       1934",
    "   Marvel,       1939",
    "    Image,       1992")
publishers <- read.csv(text = publishers, 
strip.white = TRUE)
publishers
```

Inner join
(default joining on column with same name == publisher)
```{r}
ijsp <- inner_join(superheroes, publishers)
ijsp
```

Left join
```{r}
ljsp = left_join(superheroes,publishers)
ljsp
```

full join
```{r}
fjsp <- full_join(superheroes, publishers)
fjsp
```

if the column names aren't exactly the same you use the by argument in join.
```{r}
names(publishers)
publishers <- publishers %>% select(Publisher = publisher, yr_founded)
names(publishers)
fulljoin <- full_join(superheroes, publishers, by = c("publisher" = "Publisher"))
fulljoin
```
## Reshaping --
Don't use reshape!
Use tidry::gather

```{r}
library(tidyr)
```


## dplyr and databases
```{r}
# install.packages('babynames')
# install.packages('pryr')
library(dplyr)
library(babynames)
library(pryr)

View(babynames)
str(babynames)
object_size(babynames)
```

sql lite database
```{r}
my_db <- src_sqlite("my_db.sqlite3", create = T)
```
put babies in the database
``` {r}
babys_sqlite <- copy_to(my_db,babynames, temporary = FALSE)
src_tbls(my_db)
```

look at it
```{r}
tbl(my_db,"babynames")
```

Try some dplyr.
We first specify the database,
then we specify the table we want that is in the database,
then we do our filtering and functions.

The whole first line is just collecting commands and translating into sql
Then the call of newtbl just pulls the first few rows, not the whole result.
```{r}
newtbl <- my_db %>%
     tbl("babynames") %>%
     filter(name == "Hilary")%>%
     select(year,n,name)
newtbl
```

If we want the whole result we need the collect function.
Don't run collect yet if there are going to be 10million rows.
```{r}
newtbl <- my_db %>%
     tbl("babynames") %>%
     filter(name == "Hilary")%>%
     select(year,n,name) %>% collect()
newtbl
```

Get dimension
```{r}
my_db %>%
     tbl("babynames") %>%
     filter(name == "Hilary")%>%
     select(year,n,name) %>% summarize(n=n())
```

get popular names.
BUT rank (top_n) is not supported! So... collect before you run that function
```{r}
# popular = my_db %>%
#      tbl("babynames") %>%
#      group_by(name) %>%
#      summarise(N = sum(n)) %>%
#      arrange(desc(N)) %>% top_n(100)
# popular
## GIVES ERROR
## SO...

popular = my_db %>%
     tbl("babynames") %>%
     group_by(name) %>%
     summarise(N = sum(n)) %>%
     arrange(desc(N)) %>% 
     collect() %>% top_n(100)
popular
```


```{r}
translate_sql(filter(name=="James"))
translate_sql(mean(x))
```

how female
```{r}
how_female = my_db %>% 
     tbl("babynames") %>% 
     group_by(name) %>% 
     summarize(m=mean(sex=="F"))
how_female

## What is the translation in sql?
show_query(how_female)
```

### data.table

For moderately sized stuff, this is the fastest way
Use it like you use data.frames
BUT it has funk syntax
```{r}
install.packages('data.table')
library(data.table)
library(readr)
library(babynames)
```

writing a file
```{r}
write_csv(babynames,'babynames.csv')
```

reading a file - how long does it take
```{r}
system.time(read.csv('babynames.csv'))
system.time(read_csv('babynames.csv'))
system.time(fread('babynames.csv'))

```

Using DT objects
```{r}
baby_dt = fread('babynames.csv')
class(baby_dt)
female = baby_dt[sex=="F"]
dim(female)
baby_dt[sex=="F",.(n,name,prop)]

```

fancier uses
```{r}
baby_dt[sex=="F",.(name,mean(prop))]
baby_dt[sex=="F",
        .(name,mean(prop)),name]
```

re-assign
calculate average proportion per name
:= 
```{r}
baby_dt[sex=="F",
        .(name,aveprop=mean(prop)),name]
baby_dt[,aveprop:=mean(prop),name]
baby_dt
```


